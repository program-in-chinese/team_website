---
layout: post
comments: true
title:  大疆机甲大师Python API之十二：识别郭德纲于谦
description: 
date:   2019-11-06 00:00:00 -0700
categories: Python 机甲大师
---

为测试识别行人相关接口，先用手机端对真人（自己）作了行人识别尝试，发觉对全身像比较敏感。接着用照片试了试，感觉站姿更易于被识别。

为了使实验易于重复，选择在电脑播放视频并静止画面。将机甲摄像头设置为高清，似乎效果好了点。下面是搭建的环境：
![2019-11-06_setup]({{ "/assets/2019-11-06_setup.png" | absolute_url }})

手机端开发环境中，先测试了手动使能行人识别的效果。垫高了电脑，调整距离，使识别效果稳定。见手机截图中的两个黄框：

![2019-11-06_cell识别]({{ "/assets/2019-11-06_cell识别.png" | absolute_url }})

### 代码主体
```python
def 开始():
    视觉.开启识别(行人)
    
    while True:
        if 视觉.当识别到(常量.有行人时):
            信息 = 视觉.取行人信息()
            告知(信息)
        时间.睡眠(1)
```
在机甲上完整可运行代码[在此](https://github.com/program-in-chinese/robomaster-python-samples-zh/blob/master/Python%20API%E8%A7%86%E9%A2%91%E6%BC%94%E7%A4%BA%E4%B8%8E%E4%BE%8B%E7%A8%8B/%E8%AF%86%E5%88%AB/%E8%A1%8C%E4%BA%BA.py)。每隔一秒尝试一次识别行人，在控制台输出识别信息，格式如下（源自[官方文档](https://www.dji.com/cn/robomaster-s1/programming-guide)）：

![2019-11-06_api文档]({{ "/assets/2019-11-06_api文档.png" | absolute_url }})

### 测试结果

过程中机甲位置没动，识别距离未作修改。

一、两人识别：
![2019-11-06_api识别2]({{ "/assets/2019-11-06_api识别2.png" | absolute_url }})

二、郭德纲识别：
![2019-11-06_api识别左]({{ "/assets/2019-11-06_api识别左.png" | absolute_url }})

中心点位置和两人识别时区别不大，宽度也差不多，但高度高了10%。这个，难道是没有谦大爷衬托就显高了？

三、于谦识别：
![2019-11-06_api识别右]({{ "/assets/2019-11-06_api识别右.png" | absolute_url }})

光是谦大爷的话，识别的位置上移了点，也胖点高点。

四、如果挡了腿，就识别不到了
![2019-11-06_api识别0]({{ "/assets/2019-11-06_api识别0.png" | absolute_url }})
仔细看看题图里的识别，感情是把桌子认成了谦大爷的裙子哈。
### 后感

希望放开底层接口，以便进行视觉识别的算法尝试。比如能获得视频流（或者帧）的话，再加上对第三方库的支持，用户就可以实现一些初步的人脸、物品识别等等。想起来就很美！